"""
Load exercises from artifacts/json folder.
"""
from __future__ import annotations
import os
import json
import random
from typing import List, Dict, Any, Optional


# Map topic names (from database) to chapter files (user-provided MCQs)
# ðŸŽ¯ USING PRODUCTION FOLDER (471 MCQs from MD files)
TOPIC_TO_FILES: Dict[str, List[str]] = {
    # ChÆ°Æ¡ng I: Má»‡nh Ä‘á» vÃ  Táº­p há»£p (99 MCQs)
    "Má»‡nh Ä‘á»": ["chuong_1.json"],
    "Má»‡nh Ä‘á» â€“ Táº­p há»£p": ["chuong_1.json"],
    "Táº­p há»£p": ["chuong_1.json"],
    "Táº­p há»£p â€“ CÃ¡c phÃ©p toÃ¡n": ["chuong_1.json"],
    "Ã”n táº­p ChÆ°Æ¡ng I": ["chuong_1.json"],
    
    # ChÆ°Æ¡ng II: Báº¥t phÆ°Æ¡ng trÃ¬nh (100 MCQs)
    "Báº¥t phÆ°Æ¡ng trÃ¬nh": ["chuong_2.json"],
    "Há»‡ báº¥t phÆ°Æ¡ng trÃ¬nh": ["chuong_2.json"],
    "Báº¥t phÆ°Æ¡ng trÃ¬nh - Há»‡ báº¥t phÆ°Æ¡ng trÃ¬nh": ["chuong_2.json"],
    "Ã”n táº­p ChÆ°Æ¡ng II": ["chuong_2.json"],
    
    # ChÆ°Æ¡ng III: GÃ³c lÆ°á»£ng giÃ¡c vÃ  Há»‡ thá»©c lÆ°á»£ng (101 MCQs)
    "GiÃ¡ trá»‹ lÆ°á»£ng giÃ¡c": ["chuong_3.json"],
    "GÃ³c lÆ°á»£ng giÃ¡c": ["chuong_3.json"],
    "Äá»‹nh lÃ½ cÃ´sin": ["chuong_3.json"],
    "Äá»‹nh lÃ½ sin": ["chuong_3.json"],
    "Giáº£i tam giÃ¡c": ["chuong_3.json"],
    "Há»‡ thá»©c lÆ°á»£ng giÃ¡c": ["chuong_3.json"],
    "Ã”n táº­p ChÆ°Æ¡ng III": ["chuong_3.json"],
    
    # ChÆ°Æ¡ng IV: VectÆ¡ (71 MCQs)
    "KhÃ¡i niá»‡m vectÆ¡": ["chuong_4.json"],
    "VectÆ¡": ["chuong_4.json"],
    "Tá»•ng vÃ  hiá»‡u vectÆ¡": ["chuong_4.json"],
    "TÃ­ch vectÆ¡ vá»›i sá»‘": ["chuong_4.json"],
    "TÃ­ch vÃ´ hÆ°á»›ng": ["chuong_4.json"],
    "Tá»a Ä‘á»™ vectÆ¡": ["chuong_4.json"],
    "VectÆ¡ vÃ  á»©ng dá»¥ng": ["chuong_4.json"],
    "Ã”n táº­p ChÆ°Æ¡ng IV": ["chuong_4.json"],
    
    # ChÆ°Æ¡ng V: PhÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng vÃ  Ä‘Æ°á»ng trÃ²n (100 MCQs)
    "PhÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng": ["chuong_5.json"],
    "PhÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng trÃ²n": ["chuong_5.json"],
    "ÄÆ°á»ng tháº³ng": ["chuong_5.json"],
    "ÄÆ°á»ng trÃ²n": ["chuong_5.json"],
    "Elip": ["chuong_5.json"],
    "Ã”n táº­p ChÆ°Æ¡ng V": ["chuong_5.json"],
    
    # Generic fallbacks
    "HÃ m sá»‘ â€“ Äá»“ thá»‹": ["chuong_1.json"],  # Fallback to chapter 1
}


def get_artifacts_base_path() -> str:
    """Get the base path to artifacts/production folder (user-provided MCQs)."""
    current_dir = os.path.dirname(__file__)
    artifacts_path = os.path.join(current_dir, "..", "..", "artifacts", "production")
    return os.path.abspath(artifacts_path)


def find_topic_files(topic: str) -> Optional[List[str]]:
    """Find the list of JSON files for a given topic."""
    base_path = get_artifacts_base_path()
    
    # Try exact match from mapping
    if topic in TOPIC_TO_FILES:
        file_names = TOPIC_TO_FILES[topic]
        # Verify files exist
        file_paths = []
        for file_name in file_names:
            file_path = os.path.join(base_path, file_name)
            if os.path.exists(file_path):
                file_paths.append(file_path)
        if file_paths:
            return file_paths
    
    # Try fuzzy match (case-insensitive, partial match)
    topic_lower = topic.lower()
    for mapped_topic, file_names in TOPIC_TO_FILES.items():
        if topic_lower in mapped_topic.lower() or mapped_topic.lower() in topic_lower:
            file_paths = []
            for file_name in file_names:
                file_path = os.path.join(base_path, file_name)
                if os.path.exists(file_path):
                    file_paths.append(file_path)
            if file_paths:
                return file_paths
    
    return None


def load_questions_from_files(file_paths: List[str], auto_generate_answers: bool = False) -> List[Dict[str, Any]]:
    """
    Load and merge questions from multiple JSON files.
    
    Args:
        file_paths: List of paths to JSON files
        auto_generate_answers: If True, auto-generate answers for questions without answers (SLOW!)
    
    Returns:
        List of questions with answers
    """
    all_questions = []
    
    for file_path in file_paths:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            if not isinstance(data, list):
                continue
            
            # Process each item
            for item in data:
                if not isinstance(item, dict):
                    continue
                
                # Skip theory items
                if item.get("type") == "theory":
                    continue
                
                text = item.get("text", "").strip()
                if not text:
                    continue
                
                options = item.get("options")
                answer_type = item.get("answer_type", "open")
                
                # Determine if it's MCQ with valid options
                has_valid_options = (
                    isinstance(options, list) 
                    and len(options) >= 2 
                    and all(isinstance(opt, str) and opt.strip() for opt in options)
                    and answer_type == "mcq"
                )
                
                # âœ… CHá»ˆ Láº¤Y MCQ - Skip cÃ¢u tá»± luáº­n
                if not has_valid_options:
                    continue
                
                # Always MCQ at this point (already filtered above)
                # âœ… Read difficulty from JSON answer data
                answer_data = item.get("answer", {})
                
                # Map difficulty_level string to number (1-5)
                difficulty_map = {
                    "easy": 2,
                    "medium": 3,
                    "hard": 4,
                    "very_hard": 5,
                    "very_easy": 1
                }
                
                # Get difficulty from answer metadata or use number directly
                difficulty_level = answer_data.get("difficulty_level", "medium")
                difficulty_number = answer_data.get("difficulty_number", None)
                
                # Prefer difficulty_number if available, otherwise map from level
                if difficulty_number and isinstance(difficulty_number, int) and 1 <= difficulty_number <= 5:
                    difficulty = difficulty_number
                else:
                    difficulty = difficulty_map.get(difficulty_level, 3)
                
                question = {
                    "question": text,
                    "type": "mcq",
                    "difficulty": difficulty,  # âœ… From JSON metadata
                    "options": [opt.strip() for opt in options],
                }
                
                # Check if answer exists in source data (REQUIRED for MCQ)
                if "answer" in item and item["answer"]:
                    answer = item["answer"]
                    if isinstance(answer, dict):
                        question["solution"] = answer.get("correct", "")
                        question["explanation"] = answer.get("explanation", "")
                        question["solution_steps"] = answer.get("solution_steps", [])
                        question["key_concepts"] = answer.get("key_concepts", [])
                        
                        # For MCQ, extract correct answer letter (REQUIRED)
                        correct = answer.get("correct", "")
                        if correct and len(correct) == 1 and correct.upper() in "ABCDEFGH":
                            question["correct_index"] = ord(correct.upper()) - ord('A')
                            all_questions.append(question)  # âœ… Only add if has valid answer
                        else:
                            # Skip MCQ without valid correct answer
                            continue
                    else:
                        # Skip if answer is not dict
                        continue
                else:
                    # Skip MCQ without answer (no auto-generate for speed)
                    continue
        
        except Exception as e:
            print(f"Error loading questions from {file_path}: {e}")
            continue
    
    return all_questions


def sample_questions(
    questions: List[Dict[str, Any]], 
    n: int, 
    difficulty: int,
    fmt: str
) -> List[Dict[str, Any]]:
    """
    Sample N questions from the pool and transform to exercise format.
    
    Args:
        questions: Pool of questions
        n: Number of questions to sample
        difficulty: Target difficulty (1-5) - adjusts question selection
        fmt: Format ("open", "mcq", "mixed")
    
    Returns:
        List of sampled and transformed questions
    """
    if not questions:
        return []
    
    # Filter by format if needed
    if fmt == "mcq":
        filtered = [q for q in questions if q.get("type") == "mcq"]
    elif fmt == "open":
        filtered = [q for q in questions if q.get("type") == "open"]
    else:  # mixed
        filtered = questions
    
    if not filtered:
        filtered = questions  # Fallback to all if no match
    
    # Random sample (with replacement if not enough questions)
    if len(filtered) >= n:
        sampled = random.sample(filtered, n)
    else:
        # If not enough, sample with replacement
        sampled = random.choices(filtered, k=n)
    
    # Transform to exercise format expected by frontend
    transformed = []
    for q in sampled:
        exercise = {
            "question": q.get("question", ""),  # Already transformed by load_questions_from_files
            "type": q.get("type", "open"),
            "difficulty": difficulty,
        }
        
        # MCQ specific fields
        if exercise["type"] == "mcq":
            exercise["options"] = q.get("options", [])
            exercise["correct_index"] = q.get("correct_index")
        
        # Build comprehensive solution from already-extracted fields
        # (load_questions_from_files already extracted these from answer dict)
        solution_parts = []
        
        # Add explanation if available
        explanation = q.get("explanation", "").strip()
        if explanation:
            solution_parts.append(explanation)
        
        # Add solution steps if available
        solution_steps = q.get("solution_steps", [])
        if solution_steps and isinstance(solution_steps, list) and len(solution_steps) > 0:
            solution_parts.append("\n\nðŸ“ CÃ¡c bÆ°á»›c giáº£i:")
            for i, step in enumerate(solution_steps, 1):
                if step and step.strip():
                    solution_parts.append(f"{i}. {step}")
        
        # Add key concepts if available
        key_concepts = q.get("key_concepts", [])
        if key_concepts and isinstance(key_concepts, list) and len(key_concepts) > 0:
            solution_parts.append("\n\nðŸ’¡ KhÃ¡i niá»‡m liÃªn quan:")
            for concept in key_concepts:
                if concept and concept.strip():
                    solution_parts.append(f"â€¢ {concept}")
        
        exercise["solution"] = "\n".join(solution_parts) if solution_parts else "ChÆ°a cÃ³ lá»i giáº£i chi tiáº¿t."
        
        transformed.append(exercise)
    
    return transformed


def load_exercises_from_artifacts(
    topic: str, 
    n: int, 
    difficulty: int, 
    fmt: str
) -> Optional[List[Dict[str, Any]]]:
    """
    Main function to load exercises from artifacts.
    
    Args:
        topic: Topic name (Vietnamese)
        n: Number of exercises
        difficulty: Difficulty level (1-5)
        fmt: Format ("open", "mcq", "mixed")
    
    Returns:
        List of exercises, or None if not found
    """
    file_paths = find_topic_files(topic)
    if not file_paths:
        print(f"No artifact files found for topic: {topic}")
        return None
    
    print(f"Loading questions from {len(file_paths)} file(s): {[os.path.basename(p) for p in file_paths]}")
    questions = load_questions_from_files(file_paths)
    
    if not questions:
        print(f"No questions found in files for topic: {topic}")
        return None
    
    print(f"Found {len(questions)} questions in artifacts")
    sampled = sample_questions(questions, n, difficulty, fmt)
    print(f"Sampled {len(sampled)} questions")
    
    return sampled

