from __future__ import annotations
import os
import re
import json
import uuid
import datetime as dt
from typing import List, Dict, Any, Tuple

from ..chat.retriever import retrieve
from ..chat.gemini_client import have_gemini
from .artifact_loader import load_exercises_from_artifacts


DATA_ROOT = os.path.join(os.path.dirname(__file__), ".data")


def _ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def _extract_json_block(text: str) -> str | None:
    """Extract a JSON array/object from model text output.
    Supports fenced code blocks and plain text containing a single JSON array.
    """
    if not text:
        return None
    # Try code fence ```json ... ```
    m = re.search(r"```json\s*([\s\S]*?)\s*```", text, re.IGNORECASE)
    if m:
        return m.group(1).strip()
    # Try to find first [ ... ] balanced array
    m = re.search(r"\[.*\]", text, re.DOTALL)
    if m:
        return m.group(0).strip()
    # Try to find { ... } (object) and wrap into list if needed
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if m:
        return m.group(0).strip()
    return None


def _normalize_items(raw: Any, n: int, fmt: str, difficulty: int) -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []
    if isinstance(raw, dict):
        raw = [raw]
    if isinstance(raw, list):
        for r in raw:
            if not isinstance(r, dict):
                continue
            q = str(r.get("question") or r.get("q") or r.get("text") or "").strip()
            if not q:
                continue
            typ = (r.get("type") or fmt or "open").lower()
            if typ not in ("open", "mcq"):
                typ = "open"
            item: Dict[str, Any] = {
                "question": q,
                "type": typ,
                "difficulty": int(r.get("difficulty") or difficulty or 3),
            }
            if typ == "mcq":
                opts = r.get("options") or r.get("choices")
                if isinstance(opts, list) and all(isinstance(x, str) for x in opts):
                    item["options"] = opts[:6]
                ci = r.get("correct_index")
                if isinstance(ci, int):
                    item["correct_index"] = ci
            sol = r.get("solution") or r.get("answer")
            if isinstance(sol, str):
                item["solution"] = sol
            items.append(item)
    # Final cap/pad
    items = items[:n]
    if not items:
        # Minimal fallback one item
        items = [{"question": "H√£y tr√¨nh b√†y kh√°i ni·ªám li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ n√†y.", "type": "open", "difficulty": difficulty}]
    return items


def _build_generate_prompt(topic: str, n: int, difficulty: int, fmt: str, contexts: List[Dict[str, Any]]) -> str:
    ctx_lines: List[str] = []
    for c in contexts:
        ctx_lines.append(f"- ({c.get('chunk_index')}) {c.get('preview','')}")
    ctx = "\n".join(ctx_lines) if ctx_lines else "(no context)"
    schema = (
        "Xu·∫•t ra JSON THU·∫¶N (kh√¥ng c√≥ gi·∫£i th√≠ch), l√† m·ªôt m·∫£ng c√°c object.\n"
        "M·ªói object c√≥ c√°c field: question (string), type (\"open\"|\"mcq\"), difficulty (1..5),\n"
        "options (array<string>, optional, ch·ªâ khi type=mcq), correct_index (int, optional), solution (string, optional).\n"
    )
    guide = (
        f"Ch·ªß ƒë·ªÅ: {topic}\nS·ªë l∆∞·ª£ng: {n}\nƒê·ªô kh√≥ (1-5): {difficulty}\nƒê·ªãnh d·∫°ng: {fmt}\n"
        "C√¢u h·ªèi ng·∫Øn g·ªçn, r√µ r√†ng, ti·∫øng Vi·ªát. N·∫øu mcq, m·ªói c√¢u 3-5 l·ª±a ch·ªçn.\n"
    )
    return (
        "B·∫°n l√† tr·ª£ l√Ω t·∫°o b√†i t·∫≠p To√°n 10. D·ª±a v√†o b·ªëi c·∫£nh d∆∞·ªõi ƒë√¢y, sinh b√†i t·∫≠p ph√π h·ª£p nƒÉng l·ª±c.\n"
        + schema
        + "\nB·ªëi c·∫£nh:\n"
        + ctx
        + "\n\nY√™u c·∫ßu ƒë·∫ßu ra:\n"
        + guide
    )


def _call_gemini_json(prompt: str, model_name: str = "gemini-2.5-flash-lite") -> Any:
    try:
        import google.generativeai as genai  # type: ignore
    except Exception:
        return None
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return None
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    try:
        # Prefer JSON output if supported
        resp = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.3,
            },
        )
        text = getattr(resp, "text", None) or ""
        block = _extract_json_block(text)
        if not block:
            # In case model returned pure JSON without fences
            block = text.strip()
        return json.loads(block)
    except Exception:
        return None


def generate_answer_for_question(question_data: Dict[str, Any]) -> Dict[str, Any] | None:
    """
    AI t·ª± ƒë·ªông t·∫°o ƒë√°p √°n cho c√¢u h·ªèi ch∆∞a c√≥ answer.
    
    Args:
        question_data: Dictionary ch·ª©a th√¥ng tin c√¢u h·ªèi (text, options, answer_type, etc.)
    
    Returns:
        Dictionary ch·ª©a answer v·ªõi format chu·∫©n, ho·∫∑c None n·∫øu kh√¥ng generate ƒë∆∞·ª£c
    """
    if not have_gemini():
        return None
    
    question_text = question_data.get("text", "")
    answer_type = question_data.get("answer_type", "open")
    options = question_data.get("options", [])
    chapter = question_data.get("chapter", "")
    
    if not question_text:
        return None
    
    # Build prompt d·ª±a tr√™n lo·∫°i c√¢u h·ªèi
    if answer_type == "multiple_choice" and options:
        options_text = "\n".join(options)
        prompt = f"""B·∫°n l√† gi√°o vi√™n To√°n 10 chuy√™n nghi·ªáp. H√£y tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám sau v·ªõi ƒë√°p √°n chi ti·∫øt.

Ch∆∞∆°ng: {chapter}

C√¢u h·ªèi:
{question_text}

C√°c ƒë√°p √°n:
{options_text}

H√£y tr·∫£ v·ªÅ JSON v·ªõi format sau (KH√îNG th√™m markdown code blocks):
{{
  "correct": "A",
  "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao ƒë√°p √°n n√†y ƒë√∫ng",
  "solution_steps": [
    "B∆∞·ªõc 1: ...",
    "B∆∞·ªõc 2: ...",
    "B∆∞·ªõc 3: ..."
  ],
  "key_concepts": ["Kh√°i ni·ªám 1", "Kh√°i ni·ªám 2"],
  "difficulty_level": "easy"
}}

L∆∞u √Ω:
- "correct" ch·ªâ l√† ch·ªØ c√°i A, B, C, ho·∫∑c D
- "explanation" gi·∫£i th√≠ch t·∫°i sao ƒë√°p √°n ƒë√∫ng (1-2 c√¢u)
- "solution_steps" l√† m·∫£ng c√°c b∆∞·ªõc gi·∫£i chi ti·∫øt
- "key_concepts" l√† m·∫£ng c√°c kh√°i ni·ªám to√°n h·ªçc li√™n quan
- "difficulty_level" l√† "easy", "medium", ho·∫∑c "hard"
"""
    else:
        # Open question
        prompt = f"""B·∫°n l√† gi√°o vi√™n To√°n 10 chuy√™n nghi·ªáp. H√£y tr·∫£ l·ªùi c√¢u h·ªèi t·ª± lu·∫≠n sau v·ªõi ƒë√°p √°n chi ti·∫øt.

Ch∆∞∆°ng: {chapter}

C√¢u h·ªèi:
{question_text}

H√£y tr·∫£ v·ªÅ JSON v·ªõi format sau (KH√îNG th√™m markdown code blocks):
{{
  "correct": "ƒê√°p √°n ƒë√∫ng ƒë·∫ßy ƒë·ªß ·ªü ƒë√¢y",
  "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn",
  "solution_steps": [
    "B∆∞·ªõc 1: ...",
    "B∆∞·ªõc 2: ...",
    "B∆∞·ªõc 3: ..."
  ],
  "key_concepts": ["Kh√°i ni·ªám 1", "Kh√°i ni·ªám 2"],
  "difficulty_level": "medium"
}}

L∆∞u √Ω:
- "correct" l√† c√¢u tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß, chi ti·∫øt
- "explanation" gi·∫£i th√≠ch logic c·ªßa ƒë√°p √°n (1-2 c√¢u)
- "solution_steps" l√† m·∫£ng c√°c b∆∞·ªõc gi·∫£i chi ti·∫øt
- "key_concepts" l√† m·∫£ng c√°c kh√°i ni·ªám to√°n h·ªçc li√™n quan
- "difficulty_level" l√† "easy", "medium", ho·∫∑c "hard"
"""
    
    try:
        result = _call_gemini_json(prompt, model_name="gemini-2.0-flash-exp")
        
        # Validate result structure
        if result and isinstance(result, dict):
            required_fields = ["correct", "explanation", "solution_steps", "key_concepts", "difficulty_level"]
            if all(field in result for field in required_fields):
                return result
        
        return None
    except Exception as e:
        print(f"‚ùå Error generating answer: {str(e)}")
        return None


def generate_exercises(topic: str, n: int, difficulty: int, fmt: str, top_k: int) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], str]:
    contexts = retrieve(topic, top_k=top_k)
    model_used = "artifacts"
    items: List[Dict[str, Any]] = []
    
    # Priority 1: Try to load from artifacts first (real data!)
    print(f"üîç Trying to load exercises from artifacts for topic: {topic}")
    artifact_items = load_exercises_from_artifacts(topic, n, difficulty, fmt)
    if artifact_items:
        items = artifact_items
        model_used = "artifacts"
        print(f"‚úÖ Loaded {len(items)} exercises from artifacts")
    
    # Priority 2: If no artifacts, try Gemini AI
    if not items and have_gemini():
        print(f"ü§ñ No artifacts found, trying Gemini AI...")
        prompt = _build_generate_prompt(topic, n, difficulty, fmt, contexts)
        raw = _call_gemini_json(prompt)
        if raw is not None:
            items = _normalize_items(raw, n, fmt, difficulty)
            model_used = os.getenv("GEMINI_MODEL", "gemini-2.0-flash-exp")
            print(f"‚úÖ Generated {len(items)} exercises with AI")
    
    # Priority 3: Fallback deterministic items
    if not items:
        print(f"‚ö†Ô∏è Using fallback placeholder exercises")
        for i in range(n):
            items.append({
                "question": f"[{topic}] B√†i {i+1}: H√£y tr√¨nh b√†y/gi·∫£i m·ªôt b√†i ng·∫Øn ph√π h·ª£p ƒë·ªô kh√≥ {difficulty}.",
                "type": fmt if fmt in ("open", "mcq") else "open",
                "difficulty": difficulty,
            })
            if items[-1]["type"] == "mcq":
                items[-1]["options"] = ["A", "B", "C", "D"]
                items[-1]["correct_index"] = 0
        model_used = "fallback"
    
    return items, contexts, model_used


def save_exercise_set(user_id: int, topic: str, difficulty: int, fmt: str, items: List[Dict[str, Any]], contexts: List[Dict[str, Any]], model_used: str) -> Tuple[str, Dict[str, Any]]:
    created = dt.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    set_id = f"ex_{created}_{uuid.uuid4().hex[:8]}"
    user_dir = os.path.join(DATA_ROOT, str(user_id), "exercises")
    _ensure_dir(user_dir)
    doc = {
        "id": set_id,
        "user_id": user_id,
        "topic": topic,
        "difficulty": difficulty,
        "format": fmt,
        "items": items,
        "contexts": contexts,
        "used_model": model_used,
        "created_at": created,
    }
    path = os.path.join(user_dir, f"{set_id}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(doc, f, ensure_ascii=False, indent=2)
    return path, doc


def list_user_sets(user_id: int) -> List[Dict[str, Any]]:
    user_dir = os.path.join(DATA_ROOT, str(user_id), "exercises")
    out: List[Dict[str, Any]] = []
    if not os.path.isdir(user_dir):
        return out
    for fn in os.listdir(user_dir):
        if not fn.endswith(".json"):
            continue
        path = os.path.join(user_dir, fn)
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                out.append({
                    "id": data.get("id"),
                    "topic": data.get("topic"),
                    "difficulty": data.get("difficulty"),
                    "format": data.get("format"),
                    "used_model": data.get("used_model"),
                    "created_at": data.get("created_at"),
                    "path": path,
                })
        except Exception:
            continue
    # sort by created_at desc
    out.sort(key=lambda x: x.get("created_at") or "", reverse=True)
    return out


def load_user_set(user_id: int, set_id: str) -> Dict[str, Any] | None:
    path = os.path.join(DATA_ROOT, str(user_id), "exercises", f"{set_id}.json")
    if not os.path.exists(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)
