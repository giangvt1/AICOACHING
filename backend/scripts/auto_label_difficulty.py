"""
Auto-label difficulty for all questions using Gemini AI
Ph√¢n lo·∫°i ƒë·ªô kh√≥ t·ª± ƒë·ªông cho 471 c√¢u h·ªèi To√°n 10
"""

import json
import os
import sys
import time
from typing import Dict, Any, List

# Add parent directory to path to import config
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Load .env file from both locations
from dotenv import load_dotenv
backend_dir = os.path.dirname(os.path.dirname(__file__))
app_dir = os.path.join(backend_dir, "app")

# Load from backend/.env first, then backend/app/.env (override)
load_dotenv(os.path.join(backend_dir, ".env"))
load_dotenv(os.path.join(app_dir, ".env"))

import google.generativeai as genai

# Configure Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("‚ùå GOOGLE_API_KEY not found in environment")
    print("üí° Please set it in backend/app/.env file:")
    print("   GOOGLE_API_KEY=your-api-key-here")
    sys.exit(1)

print(f"‚úÖ Found GOOGLE_API_KEY: {GOOGLE_API_KEY[:20]}...")
genai.configure(api_key=GOOGLE_API_KEY)

# Use gemini-2.5-flash-lite for better quota and quality
model = genai.GenerativeModel("gemini-2.5-flash-lite")

# System prompt for difficulty classification
SYSTEM_PROMPT = """B·∫°n l√† gi√°o vi√™n To√°n chuy√™n nghi·ªáp, chuy√™n ƒë√°nh gi√° ƒë·ªô kh√≥ c·ªßa c√¢u h·ªèi tr·∫Øc nghi·ªám To√°n l·ªõp 10.

NHI·ªÜM V·ª§: Ph√¢n t√≠ch c√¢u h·ªèi v√† ƒë√°nh gi√° ƒë·ªô kh√≥ t·ª´ 1-5.

TI√äU CH√ç ƒê√ÅNH GI√Å:

**ƒê·ªô kh√≥ 1 (Very Easy):**
- Nh·∫≠n bi·∫øt ƒë·ªãnh nghƒ©a c∆° b·∫£n
- Nh·ªõ c√¥ng th·ª©c ƒë∆°n gi·∫£n
- V√≠ d·ª•: "Ph·ªß ƒë·ªãnh c·ªßa m·ªánh ƒë·ªÅ l√† g√¨?", "C√¥ng th·ª©c sin(a+b) = ?"

**ƒê·ªô kh√≥ 2 (Easy):**
- V·∫≠n d·ª•ng tr·ª±c ti·∫øp c√¥ng th·ª©c/ƒë·ªãnh nghƒ©a
- 1 b∆∞·ªõc t√≠nh to√°n ƒë∆°n gi·∫£n
- V√≠ d·ª•: "T√≠nh sin(30¬∞)", "T√¨m ph·ªß ƒë·ªãnh c·ªßa m·ªánh ƒë·ªÅ ƒë√£ cho"

**ƒê·ªô kh√≥ 3 (Medium):**
- V·∫≠n d·ª•ng c√¥ng th·ª©c qua 2-3 b∆∞·ªõc
- K·∫øt h·ª£p 1-2 ki·∫øn th·ª©c
- V√≠ d·ª•: "Gi·∫£i b·∫•t ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t", "T√≠nh g√≥c trong tam gi√°c"

**ƒê·ªô kh√≥ 4 (Hard):**
- K·∫øt h·ª£p nhi·ªÅu ki·∫øn th·ª©c kh√°c nhau
- Suy lu·∫≠n logic ph·ª©c t·∫°p
- C·∫ßn bi·∫øn ƒë·ªïi ho·∫∑c ch·ª©ng minh
- V√≠ d·ª•: "Ch·ª©ng minh t√≠nh ch·∫•t vect∆°", "Gi·∫£i h·ªá b·∫•t ph∆∞∆°ng tr√¨nh ph·ª©c t·∫°p"

**ƒê·ªô kh√≥ 5 (Very Hard):**
- T√≠ch h·ª£p nhi·ªÅu ch∆∞∆°ng
- Suy lu·∫≠n cao c·∫•p, b√†i to√°n t·ªïng h·ª£p
- C·∫ßn k·ªπ thu·∫≠t ƒë·∫∑c bi·ªát
- V√≠ d·ª•: "B√†i to√°n h√¨nh h·ªçc k·∫øt h·ª£p vect∆° v√† l∆∞·ª£ng gi√°c", "Ch·ª©ng minh n√¢ng cao"

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
```json
{
  "difficulty": <s·ªë t·ª´ 1-5>,
  "difficulty_label": "<easy|medium|hard|very_hard>",
  "reasoning": "<gi·∫£i th√≠ch ng·∫Øn g·ªçn 1 c√¢u>"
}
```

CH√ö √ù:
- Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch th√™m
- reasoning: ti·∫øng Vi·ªát, ng·∫Øn g·ªçn
- Ph√¢n b·ªë c√¢n ƒë·ªëi: 20% easy, 40% medium, 30% hard, 10% very_hard
"""


def classify_difficulty(question_text: str, options: List[str], explanation: str, max_retries: int = 3) -> Dict[str, Any]:
    """
    Use Gemini to classify difficulty of a question with retry logic.
    
    Args:
        question_text: C√¢u h·ªèi
        options: C√°c ƒë√°p √°n
        explanation: L·ªùi gi·∫£i
        max_retries: Number of retry attempts on failure
    
    Returns:
        Dict with difficulty, difficulty_label, reasoning
    """
    # Build prompt
    options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
    
    prompt = f"""Ph√¢n lo·∫°i ƒë·ªô kh√≥ cho c√¢u h·ªèi sau:

C√ÇU H·ªéI:
{question_text}

C√ÅC ƒê√ÅP √ÅN:
{options_text}

L·ªúI GI·∫¢I:
{explanation[:500]}...

Tr·∫£ v·ªÅ JSON theo format ƒë√£ cho."""

    # Retry loop
    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                f"{SYSTEM_PROMPT}\n\n{prompt}",
                generation_config={"temperature": 0.1}
            )
            
            result_text = response.text.strip()
            
            # Extract JSON from markdown code block if present
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()
            
            result = json.loads(result_text)
            
            # Validate result
            if "difficulty" not in result or "difficulty_label" not in result:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è  Invalid format, retry {attempt + 1}/{max_retries}...")
                    time.sleep(2)
                    continue
                else:
                    print(f"‚ö†Ô∏è  Invalid response format after {max_retries} attempts, using default")
                    return {"difficulty": 3, "difficulty_label": "medium", "reasoning": "Default (invalid format)"}
            
            # Map difficulty number to label
            label_map = {1: "easy", 2: "easy", 3: "medium", 4: "hard", 5: "very_hard"}
            expected_label = label_map.get(result["difficulty"], "medium")
            
            # Override label if mismatch
            if result["difficulty_label"] != expected_label:
                result["difficulty_label"] = expected_label
            
            return result
            
        except json.JSONDecodeError as e:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è  JSON parse error, retry {attempt + 1}/{max_retries}...")
                time.sleep(2)
                continue
            else:
                print(f"‚ö†Ô∏è  JSON error after {max_retries} attempts: {e}")
                return {"difficulty": 3, "difficulty_label": "medium", "reasoning": "Default (JSON error)"}
        
        except Exception as e:
            error_msg = str(e)
            
            # Check if rate limit error
            if "429" in error_msg or "quota" in error_msg.lower():
                if attempt < max_retries - 1:
                    # Extract retry delay from error if available
                    retry_delay = 60  # Default 60s
                    if "retry_delay" in error_msg:
                        try:
                            # Try to extract seconds from error message
                            import re
                            match = re.search(r'seconds[:\s]+(\d+)', error_msg)
                            if match:
                                retry_delay = int(match.group(1)) + 5  # Add 5s buffer
                        except:
                            pass
                    
                    print(f"‚ö†Ô∏è  Rate limit hit, waiting {retry_delay}s before retry {attempt + 1}/{max_retries}...")
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"‚ö†Ô∏è  Rate limit after {max_retries} attempts")
                    return {"difficulty": 3, "difficulty_label": "medium", "reasoning": "Default (rate limit)"}
            
            # Other errors
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è  Error: {str(e)[:50]}..., retry {attempt + 1}/{max_retries}...")
                time.sleep(3)
                continue
            else:
                print(f"‚ö†Ô∏è  Error after {max_retries} attempts: {str(e)[:50]}...")
                return {"difficulty": 3, "difficulty_label": "medium", "reasoning": "Default (error)"}
    
    # Should not reach here, but just in case
    return {"difficulty": 3, "difficulty_label": "medium", "reasoning": "Default (fallback)"}


def process_chapter_file(input_path: str, output_path: str, chapter_name: str):
    """
    Process one chapter JSON file to add difficulty labels.
    
    Args:
        input_path: Input JSON file path
        output_path: Output JSON file path
        chapter_name: Chapter name for logging
    """
    print(f"\n{'='*80}")
    print(f"üìö Processing: {chapter_name}")
    print(f"{'='*80}\n")
    
    # Load questions
    with open(input_path, "r", encoding="utf-8") as f:
        questions = json.load(f)
    
    total = len(questions)
    print(f"üìä Total questions: {total}\n")
    
    # Statistics
    stats = {"easy": 0, "medium": 0, "hard": 0, "very_hard": 0}
    
    # Process each question
    for idx, q in enumerate(questions, 1):
        q_id = q.get("id", f"q{idx}")
        text = q.get("text", "")
        options = q.get("options", [])
        answer = q.get("answer", {})
        explanation = answer.get("explanation", "")
        
        # Skip if not MCQ
        if not options or not text:
            print(f"‚è≠Ô∏è  [{idx}/{total}] {q_id}: Skipped (not MCQ)")
            continue
        
        # Classify difficulty
        print(f"üîç [{idx}/{total}] {q_id}: Analyzing...", end=" ")
        
        classification = classify_difficulty(text, options, explanation)
        
        # Update answer with difficulty
        answer["difficulty_level"] = classification["difficulty_label"]
        answer["difficulty_number"] = classification["difficulty"]
        answer["difficulty_reasoning"] = classification["reasoning"]
        
        q["answer"] = answer
        
        # Update stats
        stats[classification["difficulty_label"]] += 1
        
        # Print result
        diff_emoji = {
            "easy": "üü¢",
            "medium": "üü°", 
            "hard": "üî¥",
            "very_hard": "üî¥üî¥"
        }
        emoji = diff_emoji.get(classification["difficulty_label"], "‚ö™")
        print(f"{emoji} {classification['difficulty_label']} ({classification['difficulty']}) - {classification['reasoning'][:50]}...")
        
        # Rate limiting with larger delay to avoid quota issues
        # gemini-1.5-flash: 60 RPM = 1 request/second safe
        if idx % 10 == 0:
            print(f"\n‚è∏Ô∏è  Processed {idx}/{total}, pausing 5s to respect rate limits...\n")
            time.sleep(5)
        else:
            time.sleep(1.5)  # 1.5s between requests = ~40 RPM (safe margin)
    
    # Save updated questions
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(questions, f, ensure_ascii=False, indent=2)
    
    # Print statistics
    print(f"\n{'='*80}")
    print(f"‚úÖ Completed: {chapter_name}")
    print(f"{'='*80}")
    print(f"\nüìä Difficulty Distribution:")
    print(f"   üü¢ Easy:       {stats['easy']:3d} ({stats['easy']/total*100:5.1f}%)")
    print(f"   üü° Medium:     {stats['medium']:3d} ({stats['medium']/total*100:5.1f}%)")
    print(f"   üî¥ Hard:       {stats['hard']:3d} ({stats['hard']/total*100:5.1f}%)")
    print(f"   üî¥üî¥ Very Hard: {stats['very_hard']:3d} ({stats['very_hard']/total*100:5.1f}%)")
    print(f"\nüíæ Saved to: {output_path}\n")


def main():
    """Main function to process all chapters."""
    print("\n" + "="*80)
    print("ü§ñ AUTO-LABEL DIFFICULTY FOR ALL QUESTIONS")
    print("="*80 + "\n")
    
    # Define chapters
    base_dir = os.path.join(os.path.dirname(__file__), "..", "artifacts", "production")
    
    chapters = [
        ("chuong_1.json", "Ch∆∞∆°ng I: M·ªánh ƒë·ªÅ v√† T·∫≠p h·ª£p"),
        ("chuong_2.json", "Ch∆∞∆°ng II: B·∫•t ph∆∞∆°ng tr√¨nh"),
        ("chuong_3.json", "Ch∆∞∆°ng III: G√≥c l∆∞·ª£ng gi√°c v√† H·ªá th·ª©c l∆∞·ª£ng"),
        ("chuong_4.json", "Ch∆∞∆°ng IV: Vect∆°"),
        ("chuong_5.json", "Ch∆∞∆°ng V: Ph∆∞∆°ng tr√¨nh ƒë∆∞·ªùng th·∫≥ng v√† ƒë∆∞·ªùng tr√≤n"),
    ]
    
    # Process each chapter
    total_questions = 0
    for filename, chapter_name in chapters:
        input_path = os.path.join(base_dir, filename)
        output_path = os.path.join(base_dir, filename)  # Overwrite same file
        
        # Backup original file
        backup_path = os.path.join(base_dir, f"{filename}.backup")
        if not os.path.exists(backup_path):
            with open(input_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            with open(backup_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"üíæ Backup created: {backup_path}\n")
        
        process_chapter_file(input_path, output_path, chapter_name)
        
        # Count questions
        with open(output_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            total_questions += len(data)
    
    # Final summary
    print("\n" + "="*80)
    print("üéâ ALL CHAPTERS COMPLETED!")
    print("="*80)
    print(f"\n‚úÖ Total questions labeled: {total_questions}")
    print(f"\nüí° Next steps:")
    print(f"   1. Review the labeled questions")
    print(f"   2. Update artifact_loader.py to read difficulty_level")
    print(f"   3. Test with different difficulty filters")
    print(f"\nüîÑ To restore backup: cp *.backup *.json")
    print("="*80 + "\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

